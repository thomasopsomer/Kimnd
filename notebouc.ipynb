{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pkl\n",
    "from os import path\n",
    "from ast import literal_eval\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "import utils\n",
    "import flat_dataset\n",
    "from gow import tw_idf\n",
    "import temporal_features\n",
    "import textual_features\n",
    "from greetings import *\n",
    "from average_precision import mapk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the address book of each user\n",
    "def address_book_users(df):\n",
    "    book = df.groupby(\"sender\").recipients.sum()\n",
    "    book = book.map(lambda x: set(x))\n",
    "    return book\n",
    "\n",
    "\n",
    "### Predicting for each user ###\n",
    "def add_recipients(df, all_emails):\n",
    "    \"\"\"all_emails: all ID contacts of all users\"\"\"\n",
    "    user = df[\"sender\"].iloc[0] # ID of the user\n",
    "    emails = all_emails[user]\n",
    "    df[\"emails\"] = str(list(emails))\n",
    "    df[\"emails\"] = df[\"emails\"].map(literal_eval)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_test_set(test_user):\n",
    "    \"\"\"test_user: the DataFrame of the test for a specific sender\n",
    "    features: the features extracted\n",
    "    emails: list of all email\n",
    "    reg: the trained predictor\"\"\"\n",
    "    # Create a dataset with all the possible combinations (userID, mid, contactID)\n",
    "    test_user = add_recipients(test_user, contacts)\n",
    "    test_user = utils.flatmap(test_user, \"emails\", \"recipient\", np.string_)\n",
    "\n",
    "    # Some renaming\n",
    "    test_user = test_user[[\"sender\", \"recipient\", \"mid\", \"body\"]]\n",
    "    return test_user\n",
    "\n",
    "\n",
    "def split_train_dev_set(df, percent=0.2):\n",
    "    \"\"\"\n",
    "    split dataset in train and dev set\n",
    "    for each sender, we put the a percentage of the last message\n",
    "    he sent in the dev set :)\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    dev = []\n",
    "    for k, g in df.groupby(\"sender\")[\"mid\", \"recipients\"]:\n",
    "        n_msg = g.shape[0]\n",
    "        n_dev = int(n_msg * percent)\n",
    "        g = g.sort_values(\"date\")\n",
    "        g_train = g[:-n_dev]\n",
    "        g_dev = g[-n_dev:]\n",
    "        train.append(g_train)\n",
    "        dev.append(g_dev)\n",
    "    # concat all dataframe\n",
    "    df_train = pd.concat(train, axis=0).sort_index()\n",
    "    df_dev = pd.concat(dev, axis=0).sort_index()\n",
    "    return df_train, df_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def greeting_value(body, recipient, greets, names):\n",
    "    \"\"\"\n",
    "    for a message body and a recipient, return 1 if the message contains an\n",
    "    appropriate greeting -1 if the message contains a greeting for somebody\n",
    "    else and 0 otherwise\n",
    "    \"\"\"\n",
    "    greet = detect_greetings(body, names)\n",
    "    if recipient not in greets:\n",
    "        return 0\n",
    "    rec_names = recipient.split('@')[0]\n",
    "    if '.' in recipient:\n",
    "        rec_names = rec_names.split(\".\")\n",
    "    else:\n",
    "        rec_names = [rec_names]\n",
    "    rec_names = map(lambda n: (n, 1), rec_names)\n",
    "\n",
    "    # a function that create a function that score the best\n",
    "    def filtre(threshold):\n",
    "        return lambda word: (word[0] in greet) and (word[1] > threshold)\n",
    "    if len(greet) == 0:\n",
    "        return 0.\n",
    "    # import pdb; pdb.set_trace()\n",
    "    if len(filter(filtre(0.5), rec_names + greets[recipient])) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "\n",
    "def search_greetings(dataset, threshold=0.2):\n",
    "    \"\"\"\n",
    "    we create a dictionary where we list the names of all 'greetings' used for\n",
    "    a recipient\n",
    "    \"\"\"\n",
    "    firstnames = parse_firstnames(dataset)\n",
    "    lastnames = parse_lastnames(dataset)\n",
    "    names = firstnames + lastnames\n",
    "    # nlp = get_custom_spacy()\n",
    "    i = 0\n",
    "    greets = {}\n",
    "    for ind, row in dataset.iterrows():\n",
    "        # greet = utils.extract_names(row[\"body\"], nlp)\n",
    "        greet = detect_greetings(row[\"body\"], names)\n",
    "        for rec in row[\"recipients\"]:\n",
    "            if rec not in greets:\n",
    "                greets[rec] = {}\n",
    "            else:\n",
    "                cnt = Counter(greet)\n",
    "                for gr in cnt.keys():\n",
    "                    if gr not in greets[rec]:\n",
    "                        greets[rec][gr] = 0\n",
    "                    greets[rec][gr] += float(cnt[gr]) / len(row[\"recipients\"])\n",
    "    for rec in greets.keys():\n",
    "        greets[rec] = sorted(\n",
    "            greets[rec].items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "    # filter extremes\n",
    "    for rec in greets.keys():\n",
    "        greets[rec] = filter(lambda w: w[1] > threshold, greets[rec])[:3]\n",
    "\n",
    "\n",
    "    return greets, names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the files\n",
      "Preprocessing messages\n"
     ]
    }
   ],
   "source": [
    "TEST = True\n",
    "TYPE_IDF = \"tw_idf\"\n",
    "\n",
    "print \"Loading the files\"\n",
    "dataset_path = \"data/training_set.csv\"\n",
    "dataset_path2 = \"data/test_set.csv\"\n",
    "mail_path = \"data/training_info.csv\"\n",
    "mail_path2 = \"data/test_info.csv\"\n",
    "lda_path = \"LDA/LDA_results.csv\"\n",
    "\n",
    "train_df = utils.load_dataset(dataset_path, mail_path, train=True, flat=True)\n",
    "train_df_not_flat = utils.load_dataset(dataset_path, mail_path, train=True, flat=False)\n",
    "test_df = utils.load_dataset(dataset_path2, mail_path2, train=False)\n",
    "\n",
    "# LDA\n",
    "lda_df = pd.read_csv(lda_path)\n",
    "\n",
    "## TEST\n",
    "if TEST:\n",
    "    train_df_not_flat, test_df = split_train_dev_set(train_df_not_flat, percent=0.06)\n",
    "    train_df = train_df[train_df.mid.isin(train_df_not_flat.mid)]\n",
    "    recips_test = test_df[[\"mid\", \"recipients\"]]\n",
    "    test_df = test_df.drop(\"recipients\", axis=1)\n",
    "\n",
    "print \"Preprocessing messages\"\n",
    "train_df_not_flat = utils.preprocess_bodies(train_df_not_flat, type=\"train\")\n",
    "test_df = utils.preprocess_bodies(test_df, type=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting time features\n",
      "Getting the greeting features\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Temporal features #\n",
    "#####################\n",
    "\n",
    "time_path = \"time_features.csv\"\n",
    "if TEST:\n",
    "    time_path = \"time_features_test.csv\"\n",
    "if path.exists(time_path):\n",
    "    print \"Getting time features\"\n",
    "    time_features = pd.read_csv(time_path)\n",
    "else:\n",
    "    print \"Handling time\"\n",
    "    origine_time = train_df[\"date\"].min()\n",
    "    train_df[\"time\"] = (train_df[\"date\"] - origine_time).apply(lambda x: x.seconds)\n",
    "\n",
    "    print \"Time features extraction\"\n",
    "    time = train_df[\"time\"].max() + 1;\n",
    "    time_features = temporal_features.get_features_out_in(train_df, time)\n",
    "    time_features.to_csv(time_path, sep=\",\", index=False)\n",
    "\n",
    "print \"Getting the greeting features\"\n",
    "# Greetings #\n",
    "greets, name = search_greetings(train_df_not_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting global text features\n",
      "Computing and storing tw-idf of all messages\n",
      "Getting the averages dictionaries for outgoing and incoming messages\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# Textual features #\n",
    "#####################\n",
    "\n",
    "if TYPE_IDF == \"tw_idf\":\n",
    "    print \"Extracting global text features\"\n",
    "    idf_path = \"idf.pkl\"\n",
    "    if path.exists(idf_path):\n",
    "        idf = pkl.load(open(idf_path, \"rb\"))\n",
    "        id2word = pkl.load(open(\"id2word.pkl\", \"rb\"))\n",
    "        texts = list(train_df_not_flat[\"tokens\"])\n",
    "        avg_len = sum(len(terms) for terms in texts) / len(texts)\n",
    "    else:\n",
    "        idf, id2word, avg_len = textual_features.get_global_text_features(list(train_df_not_flat[\"tokens\"]))\n",
    "        with open(idf_path, \"w\") as f:\n",
    "            pkl.dump(idf, f)\n",
    "        with open(\"id2word.pkl\", \"w\") as f:\n",
    "            pkl.dump(id2word, f)\n",
    "\n",
    "    print \"Computing and storing tw-idf of all messages\"\n",
    "    pickle_path = \"twidf_dico_train.pkl\"\n",
    "    if TEST:\n",
    "        pickle_path = \"twidf_dico_train_test.pkl\"\n",
    "    if path.exists(pickle_path):\n",
    "        idf_dico = pkl.load(open(pickle_path, \"rb\"))\n",
    "    else:\n",
    "        idf_dico = {}\n",
    "        for ind, row in train_df_not_flat.iterrows():\n",
    "            if (ind+1) % 1000 == 0: print \"Processesed \", ind+1\n",
    "            mid = row[\"mid\"]\n",
    "            tokens = row[\"tokens\"]\n",
    "            idf_dico[mid] = tw_idf(tokens, idf, id2word, avg_len, window=5)\n",
    "        with open(pickle_path, \"w\") as f:\n",
    "            pkl.dump(idf_dico, f)\n",
    "\n",
    "    pickle_path = \"twidf_dico_test.pkl\"\n",
    "    if TEST:\n",
    "        pickle_path = \"twidf_dico_test_test.pkl\"\n",
    "    if path.exists(pickle_path):\n",
    "        idf_dico_test = pkl.load(open(pickle_path, \"rb\"))\n",
    "    else:\n",
    "        idf_dico_test = {}\n",
    "        for ind, row in test_df.iterrows():\n",
    "            if (ind+1) % 1000 == 0: print \"Processesed \", ind+1\n",
    "            mid = row[\"mid\"]\n",
    "            tokens = row[\"tokens\"]\n",
    "            idf_dico_test[mid] = tw_idf(tokens, idf, id2word, avg_len, window=5)\n",
    "        with open(pickle_path, \"w\") as f:\n",
    "            pkl.dump(idf_dico_test, f)\n",
    "\n",
    "    print \"Getting the averages dictionaries for outgoing and incoming messages\"\n",
    "    # Computes the average tw idf vector (incoming)\n",
    "    dict_tuple_mids_in = train_df.groupby([\"recipient\", \"sender\"])[\"mid\"].apply(list).to_dict()\n",
    "    for tupl in dict_tuple_mids_in.keys():\n",
    "        dict_tuple_mids_in[tupl] = np.average(np.array([idf_dico[m].toarray() for m in dict_tuple_mids_in[tupl]]), axis=0)\n",
    "        dict_tuple_mids_in[tupl] = csr_matrix(dict_tuple_mids_in[tupl])\n",
    "\n",
    "    # Computes the average tw idf vector (outgoing)\n",
    "    dict_tuple_mids_out = train_df.groupby([\"sender\", \"recipient\"])[\"mid\"].apply(list).to_dict()\n",
    "    for tupl in dict_tuple_mids_out.keys():\n",
    "        dict_tuple_mids_out[tupl] = np.average(np.array([idf_dico[m].toarray() for m in dict_tuple_mids_out[tupl]]), axis=0)\n",
    "        dict_tuple_mids_out[tupl] = csr_matrix(dict_tuple_mids_out[tupl])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#####Â TF-IDF #####\n",
    "\n",
    "if TYPE_IDF == \"tf_idf\":\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer=lambda x: x, ngram_range=(1, 1), min_df=5, stop_words='english')\n",
    "\n",
    "    print \"Computing and storing tf-idf of all messages\"\n",
    "    pickle_path = \"tfidf_dico_train.pkl\"\n",
    "    if TEST:\n",
    "        pickle_path = \"tfidf_dico_train_test.pkl\"\n",
    "    if path.exists(pickle_path):\n",
    "        idf_dico = pkl.load(open(pickle_path, \"rb\"))\n",
    "    else:\n",
    "        idf_dico = {}\n",
    "        tfidf_matrix = tf.fit_transform(train_df_not_flat.tokens)\n",
    "        ind = 0\n",
    "        for row in train_df_not_flat.iterrows():\n",
    "            if (ind+1) % 1000 == 0: print \"Processed \", ind+1\n",
    "            idf_dico[row[1].mid] = tfidf_matrix[ind]\n",
    "            ind += 1\n",
    "        with open(pickle_path, \"w\") as f:\n",
    "            pkl.dump(idf_dico, f)\n",
    "\n",
    "    pickle_path = \"tfidf_dico_test.pkl\"\n",
    "    if TEST:\n",
    "        pickle_path = \"tfidf_dico_test_test.pkl\"\n",
    "    if path.exists(pickle_path):\n",
    "        idf_dico_test = pkl.load(open(pickle_path, \"rb\"))\n",
    "    else:\n",
    "        idf_dico_test = {}\n",
    "        tfidf_matrix_test = tf.transform(test_df.tokens)\n",
    "        ind = 0\n",
    "        for row in test_df.iterrows():\n",
    "            if (ind+1) % 1000 == 0: print \"Processed \", ind+1\n",
    "            idf_dico_test[row[1].mid] = tfidf_matrix_test[ind]\n",
    "            ind += 1\n",
    "        with open(pickle_path, \"w\") as f:\n",
    "            pkl.dump(idf_dico_test, f)\n",
    "    print \"Getting the averages dictionaries for outgoing and incoming messages\"\n",
    "    # Computes the average tw idf vector (incoming)\n",
    "    dict_tuple_mids_in = train_df.groupby([\"recipient\", \"sender\"])[\"mid\"].apply(list).to_dict()\n",
    "    for tupl in dict_tuple_mids_in.keys():\n",
    "        dict_tuple_mids_in[tupl] = np.average(np.array([idf_dico[m].toarray() for m in dict_tuple_mids_in[tupl]]), axis=0)\n",
    "        dict_tuple_mids_in[tupl] = csr_matrix(dict_tuple_mids_in[tupl])\n",
    "\n",
    "    # Computes the average tw idf vector (outgoing)\n",
    "    dict_tuple_mids_out = train_df.groupby([\"sender\", \"recipient\"])[\"mid\"].apply(list).to_dict()\n",
    "    for tupl in dict_tuple_mids_out.keys():\n",
    "        dict_tuple_mids_out[tupl] = np.average(np.array([idf_dico[m].toarray() for m in dict_tuple_mids_out[tupl]]), axis=0)\n",
    "        dict_tuple_mids_out[tupl] = csr_matrix(dict_tuple_mids_out[tupl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for the ranking\n",
      "Generating positive and negative pairs\n",
      "Textual features for the train pairs\n",
      "Getting the test set ready\n",
      "Adding textual features to the test set\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "# Classifier #\n",
    "###############\n",
    "\n",
    "print \"Preparing for the ranking\"\n",
    "# Extract all the emails of the database\n",
    "emails = set(train_df[\"sender\"]).union(set(train_df[\"recipient\"]))\n",
    "\n",
    "# Get all contacts for each user\n",
    "contacts = time_features.groupby(\"user\").contact.apply(set)\n",
    "\n",
    "print \"Generating positive and negative pairs\"\n",
    "# Get the positive and negative pairs for the classifier\n",
    "pairs_train = flat_dataset.make_flat_dataset(train_df_not_flat, contacts, 1.0, num_cores=4)\n",
    "\n",
    "# Adding textual features\n",
    "print \"Textual features for the train pairs\"\n",
    "pairs_train['outgoing_txt'] = textual_features.text_similarity_new(\n",
    "    pairs_train, idf_dico, dict_tuple_mids_out)\n",
    "pairs_train['incoming_txt'] = textual_features.text_similarity_new(\n",
    "    pairs_train, idf_dico, dict_tuple_mids_in)\n",
    "\n",
    "greeting_feature = np.empty(pairs_train['incoming_txt'].shape[0])\n",
    "ind = 0\n",
    "for row in pairs_train.itertuples():\n",
    "    greeting_feature[ind] = greeting_value(\n",
    "            row.body, row.recipient, greets, name)\n",
    "    ind += 1\n",
    "pairs_train[\"greet\"] = greeting_feature\n",
    "\n",
    "\n",
    "# Renaming\n",
    "pairs_train = pairs_train.rename(columns={\"sender\":\"user\", \"recipient\": \"contact\"})\n",
    "pairs_train = pairs_train[[\"user\", \"contact\", \"mid\", \"incoming_txt\", \"outgoing_txt\", \"label\", \"greet\"]]\n",
    "\n",
    "print \"Getting the test set ready\"\n",
    "test_pairs = test_df.groupby(\"sender\").apply(\n",
    "    lambda test_user: get_test_set(test_user))\n",
    "test_pairs = test_pairs.reset_index(drop=True)\n",
    "\n",
    "print \"Adding textual features to the test set\"\n",
    "test_pairs['outgoing_txt'] = textual_features.text_similarity_new(\n",
    "    test_pairs, idf_dico_test, dict_tuple_mids_out)\n",
    "test_pairs['incoming_txt'] = textual_features.text_similarity_new(\n",
    "    test_pairs, idf_dico_test, dict_tuple_mids_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "greeting_feature = np.empty(test_pairs['incoming_txt'].shape[0])\n",
    "index = 0\n",
    "for row in test_pairs.itertuples():\n",
    "    greeting_feature[index] = greeting_value(\n",
    "            row.body, row.recipient, greets, name)\n",
    "    index += 1\n",
    "test_pairs[\"greet\"] = greeting_feature\n",
    "\n",
    "test_pairs = test_pairs.rename(columns={\"sender\": \"user\", \"recipient\": \"contact\"})\n",
    "test_pairs = test_pairs[[\"user\", \"contact\", \"mid\", \"incoming_txt\", \"outgoing_txt\", \"greet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b7e6e0797d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Predictions\n",
      "0.111111111111\n",
      "Predictions\n",
      "0.257455632716\n",
      "Predictions\n",
      "1.0\n",
      "Predictions\n",
      "0.169312169312\n",
      "Predictions\n",
      "0.166666666667\n",
      "Predictions\n",
      "0.015873015873\n",
      "Predictions\n",
      "0.0324074074074\n",
      "Predictions\n",
      "0.00735294117647\n",
      "Predictions\n",
      "0.0436507936508\n",
      "Predictions\n",
      "0.0590277777778\n",
      "Predictions\n",
      "0.125\n",
      "Predictions\n",
      "0.678571428571\n",
      "Predictions\n",
      "0.1875\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.738888888889\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0187878787879\n",
      "Predictions\n",
      "0.305555555556\n",
      "Predictions\n",
      "0.243075396825\n",
      "Predictions\n",
      "0.009703595724\n",
      "Predictions\n",
      "0.00646219135802\n",
      "Predictions\n",
      "0.488888888889\n",
      "Predictions\n",
      "0.75\n",
      "Predictions\n",
      "0.151587301587\n",
      "Predictions\n",
      "0.285092592593\n",
      "Predictions\n",
      "0.0625\n",
      "Predictions\n",
      "0.20582010582\n",
      "Predictions\n",
      "0.429166666667\n",
      "Predictions\n",
      "0.0489130434783\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.134801587302\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.314283234127\n",
      "Predictions\n",
      "0.142857142857\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.102857142857\n",
      "Predictions\n",
      "0.393333333333\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0815476190476\n",
      "Predictions\n",
      "0.0615942028986\n",
      "Predictions\n",
      "0.0868055555556\n",
      "Predictions\n",
      "0.207142857143\n",
      "Predictions\n",
      "0.0856060606061\n",
      "Predictions\n",
      "0.205396825397\n",
      "Predictions\n",
      "0.19696969697\n",
      "Predictions\n",
      "0.202380952381\n",
      "Predictions\n",
      "0.511904761905\n",
      "Predictions\n",
      "0.72\n",
      "Predictions\n",
      "0.05\n",
      "Predictions\n",
      "0.125\n",
      "Predictions\n",
      "0.120833333333\n",
      "Predictions\n",
      "0.0357142857143\n",
      "Predictions\n",
      "0.100988582568\n",
      "Predictions\n",
      "0.0185185185185\n",
      "Predictions\n",
      "0.0119047619048\n",
      "Predictions\n",
      "0.125\n",
      "Predictions\n",
      "0.0104166666667\n",
      "Predictions\n",
      "0.276\n",
      "Predictions\n",
      "0.279248366013\n",
      "Predictions\n",
      "0.625\n",
      "Predictions\n",
      "0.108571428571\n",
      "Predictions\n",
      "1.0\n",
      "Predictions\n",
      "0.042270531401\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.5\n",
      "Predictions\n",
      "0.220899470899\n",
      "Predictions\n",
      "0.0218148148148\n",
      "Predictions\n",
      "0.0988888888889\n",
      "Predictions\n",
      "0.833333333333\n",
      "Predictions\n",
      "0.519587301587\n",
      "Predictions\n",
      "0.08165374677\n",
      "Predictions\n",
      "0.04\n",
      "Predictions\n",
      "0.625\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0369883040936\n",
      "Predictions\n",
      "0.24843358396\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.186666666667\n",
      "Predictions\n",
      "0.126984126984\n",
      "Predictions\n",
      "0.0555555555556\n",
      "Predictions\n",
      "0.115702947846\n",
      "Predictions\n",
      "0.00333333333333\n",
      "Predictions\n",
      "0.5\n",
      "Predictions\n",
      "0.192013888889\n",
      "Predictions\n",
      "0.0181818181818\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0361290322581\n",
      "Predictions\n",
      "0.25\n",
      "Predictions\n",
      "0.143333333333\n",
      "Predictions\n",
      "0.691319444444\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0404761904762\n",
      "Predictions\n",
      "0.755555555556\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.0666666666667\n",
      "Predictions\n",
      "0.0456923076923\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.6\n",
      "Predictions\n",
      "0.129166666667\n",
      "Predictions\n",
      "0.0\n",
      "Predictions\n",
      "0.46875\n",
      "Predictions\n",
      "0.0120481927711\n",
      "Predictions\n",
      "0.00833333333333\n",
      "Predictions\n",
      "0.0779860291224\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-029fb6526746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# clf = RandomForestClassifier(n_estimators=50, random_state=42, oob_score=True, n_jobs=-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print clf.oob_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         sample_weight = np.asarray([]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    524\u001b[0m             raise ValueError(\n\u001b[1;32m    525\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                 % len(cls))\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1"
     ]
    }
   ],
   "source": [
    "print \"Training\"\n",
    "# Train arrays\n",
    "scores = []\n",
    "list_sender = np.unique(test_df['sender'].tolist())\n",
    "res_all = pd.DataFrame(columns=[\"mid\", \"contact\", \"recipients\"])\n",
    "for user in list_sender[107:]:\n",
    "    pairs_train_user = pairs_train[pairs_train.user == user]\n",
    "    X_train = pairs_train_user.merge(time_features, how=\"left\", on=[\"contact\", \"user\"]).merge(lda_df, how=\"left\", on=\"mid\")\n",
    "\n",
    "    X_train = X_train.fillna(0)\n",
    "    y_train = X_train[\"label\"].values\n",
    "    X_train = X_train.set_index([\"contact\", \"mid\", \"user\"])\n",
    "    X_train = X_train.drop([\"label\"], axis=1)\n",
    "    X_train = X_train.values\n",
    "\n",
    "    # Training\n",
    "    # clf = RandomForestClassifier(n_estimators=50, random_state=42, oob_score=True, n_jobs=-1)\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    #print clf.oob_score_\n",
    "\n",
    "    pairs_test_user = test_pairs[test_pairs.user == user]\n",
    "    # Getting the arrays for the prediction\n",
    "    X_test = pairs_test_user.merge(time_features, how=\"left\", on=[\"contact\", \"user\"]).merge(lda_df, how=\"left\", on=\"mid\")\n",
    "    X_test = X_test.fillna(0)\n",
    "    X_test = X_test.set_index([\"contact\", \"mid\", \"user\"])\n",
    "    test_index = X_test.index\n",
    "    X_test = X_test.values\n",
    "\n",
    "    print \"Predictions\"\n",
    "    # Predictions\n",
    "    #pred = clf.predict_proba(X_test)[:, clf.classes_ == 1]\n",
    "    pred = clf.predict(X_test)\n",
    "    pred = pd.DataFrame(pred, columns=[\"pred\"], index=test_index).reset_index()\n",
    "\n",
    "    # We take the top 10 for each mail\n",
    "    res = pred.groupby(\"mid\").apply(lambda row: row.sort_values(by=\"pred\", ascending=False).head(10)).reset_index(drop=True)\n",
    "    res = res[[\"mid\", \"contact\"]]\n",
    "    res = res.groupby(\"mid\").contact.apply(list).reset_index()\n",
    "    res[\"recipients\"] = res.contact.map(lambda x: ' '.join(x))\n",
    "    res_all = res_all.append(res)\n",
    "    res_all[\"mid\"] = res_all[\"mid\"].astype(np.int32)\n",
    "    # results\n",
    "    if TEST:\n",
    "        res = res.sort_values(by=\"mid\")\n",
    "        recips_test_user = recips_test[recips_test.mid.isin(res.mid)]\n",
    "        recips_test_user = recips_test_user.sort_values(by=\"mid\")\n",
    "        print mapk(recips_test_user[\"recipients\"].tolist(), res[\"contact\"].tolist())\n",
    "        scores.append(mapk(recips_test_user[\"recipients\"].tolist(), res[\"contact\"].tolist()))\n",
    "\n",
    "if TEST:\n",
    "    print \"Final mean score:\", np.mean(scores)\n",
    "else:\n",
    "    res_all.to_csv(\"results_time_text_all.csv\", columns=[\"mid\", \"recipients\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final mean score: 0.195526538034\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if TEST:\n",
    "    print \"Final mean score:\", np.mean(scores)\n",
    "else:\n",
    "    res_all.to_csv(\"results_time_text_all.csv\", columns=[\"mid\", \"recipients\"], index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([106]),)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(list_sender ==user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
